 ### 1) Есть 2 prometheus в конфедерации, в один летит шквал метрик от серверов, метрики имеют общий префикс systemd_*_*_* и нужно на нём ограничить фильтром так, чтобы {state="Active"} пропускались, а {state="Disabled"} не пропускались. в какую сторону посмотрите?

Подскажите пожалуйста, что за конфедерация????
Если подрузамевалось Federation, то добавлю два фильтра для метрики, именно фильтр что бы искал префикс `systemd_*_*_*` в совокупе с `state="Active`
Метрика будет поступать с учтом "склейки" двух фильтро указаных в поле `'match[]'`

```scrape_configs:
  - job_name: 'federate'
    scrape_interval: 15s
    honor_labels: true
    metrics_path: '/federate'
    params:
      'match[]':
        - '{state="Active"}'
        - '{__name__=~"systemd_*_*_*"}'
    static_configs:
      - targets:
        - 'source-prometheus-1:9090'
        - 'source-prometheus-2:9090'
 ```



### 2) за сколько сможете написать ansible-playbook который раскатает strongswan сервер к которому могут подключиться iphone, mac, windows для среднего офиса, vpn-сервер стоит за NAT, Cisco 2901? (50 пользователей, логины/пароли статические). Для простоты считаем, что циско-админ пробросит нам порты, какие попросим.

### 3) Имеется сильно нагруженный пользователями сервер на php/mysql стеке, проблемы: тормозит, "ресурс недоступен". что будете смотреть в каком порядке, как будете действовать? 36vCPU, 80Gb vRAM, 2Tb vDISK (SAN)

Я в SQL вообще не силён, так как эту тему к сожалению пока не разбирал. Но предполагаю чисто логически, что тут могут быть не сколько причин:
- Если запросы от пользователей зависают, то ограничеть время на выполнение операции к примеру 2 минуты ( Это поможет стабилизировать работу в системе)
- Какая-то из таблиц в БД слишком разрослась и при обработке запросов к данной БД, включающих все записи, СУБД не успевает обработать данный запрос.
- Что касается "ресурс не доступен" то тут всего скоре исчерпывается RAM, поможет  шардирование данных, установка дополнительного модуля RAM, разрешение использование СВОП - снижает быстродействие, настроить Out-Of-Memory Killer на завершение процесса который "сжирает всю RAM"  в последнюю очередь (возможно есть что-то, что можно безболезненно убить)


### 4)  Кейс: клиентская команда разработки из двух человек ведет проект на стеке php/mysql. Устоявшиеся процессы выглядят следующим образом:
А. каждый из разработчиков ведет разработку своей части сервиса на локальной копии проекта (в контейнере). Изменения пушатся в бесплатный репозиторий на github.

Б. деплой изменений на боевое окружение производится средствами git, непосредственно на единственном сервере приложений боевого окружения (pull нужной ветки из репозитория github).
Сервис развивается, в команду берут еще двух разработчиков.
#### Порекомендуйте изменение workflow и инструменты, которые позволили бы этой команде продолжить разработку сервиса, избежав организационных и технических проблем.
В интернете искать не стал, так как работал с этим инструментом, вернее изучал его - инструмент называется `github flow` Суть в том, что там организовываются ветки:
1) `master` - главная ветка, в ней всегда должен находится код, готовый к исполнению ( деплою )
2) `develop` - главная ветка, в ней находится весь код который в метке `master` + новые функции, по сути на ней происходят тесты и готовится отправка к пользователю.
3) `feature` - в этой ветки, как раз таки разработываются новые функциональности, либо дорабатывают уже имеющиеся, создаётся из ветки `develop`, после завршения работы над новой функциональность, смерживается с веткой `develop`. Самая долгоживущая ветка.
4) `hotfix` - ветка для быстрого фикса бага. Эта ветка создаётся из ветки `master` и далее мержится в ветку `develop` и `master`, делается для того, что бы исправление было в обоих версих приложения.
5) `release` - ветка нужня для поставления новых измений в продакшен,создаётся из ветки `develop`, мержится в ветку `master` и `develop` с созданием тега, для отслеживания версии релиза.

`Итог:` Для выпусков релиза используется специальная ветка, одна команда  может дорабатывать текущий релиз, а другая команда продолжает работу над 
        функциями для следующего релиза.
        В ветках `feature/pety,feature/vova,feature/lesha и т.д (смотря сколько сотрудинков и поручений)` работают разные сотрудники ,которые делают разный компонент (функционал)  приложения, и после этого все новые фичи мержат в ветку `develop`.

### 5) Взять чистую виртуальную машину в virtualbox на ubuntu 18.04, написать плейбук ansible который делает следующее:
 - ставит nginx, zsh, wget
 - клонирует из git в /var/www/ очень простую  web страничку "Under construction"
 - кладет новую конфигурацию nginx которая направляет на эту страничку
 - настраивает в sysctl параметр fs.files-max в 1204000 и somaxconn в 65535
 - прописывает на этой машинке 2 разных ssh ключа в /root
 - результат в git на github в приватном репозитории
```
############
# PLAYBOOK #
############
---
- hosts: "all"
  become: true
  tasks:
  
  # NGINX
  - name: "Install nginx via apt"
    ansible.builtin.apt:
      name: "nginx"
      state: "latest"
      update_cache: true

  - name: "Copy web page index.html"
    get_url:
      url: "https://raw.githubusercontent.com/AleksandrZolnikov/tasks/main/index.html?token=ASF2JGUJWKTVXRB7YFHGUSLBKHOBC"
      dest: "/var/www/index.html"
      mode: '0644'
      
  - name: "Copy default"
    ansible.builtin.copy: 
      src: "default" # - файл в репозитории, можете посмотреть
      dest: "/etc/nginx/sites-available/default"  
      mode: "0644" 
      
 # ZSH
  - name: "Install ZSH apt"
    ansible.builtin.apt:
      name: "zsh"
      state: "latest"
      update_cache: true

  # Install wget

  - name: "Install wget apt"
    ansible.builtin.apt:
      name: "wget"
      state: "latest"
      update_cache: true
      
      
  - name: "Sysctl options"
    sysctl:
      reload: yes
      name: "fs.file-max"
      value: "1204000"
      state: present
      
 - name: "Sysctl options_1"
    sysctl:
      reload: yes
      name: "net.core.somaxconn"
      value: "65535"
      state: present

  - name: "Reload nginx"
    ansible.builtin.service:
      name: "nginx"
      state: "reloaded"
      
# Я если честно не понял вопроса вашего,из данного контекста не совсем понятна история происхождения ключей, но каждый раз ансиблом генерировать ключи это тоже не правильно, потому что тогда, будем их плодить после каждого запуска. Извините если задаю глупые вопросы, ансбли изучаю третий день, и то мельком параллельно с работой.
А так, проще было использовать модуль ansible.builtin.copy и скопировать сгенерированые ключи просто в папочку root на удалённом хосте. Я просто запутался в формулировки вашего вопроса, и боюсь что этот пункт вообще не правильно сделал.

- name: Set authorized key in alternate location
  ansible.posix.authorized_key:
    user: jon
    state: present
    key: "{{ lookup('file', '/home/jon/.ssh/id_rsa_1.pub') }}"
    path: /root # но они не будут работать.
    manage_dir: False

 - name: Set authorized key in alternate location
  ansible.posix.authorized_key:
    user: petya
    state: present
    key: "{{ lookup('file', '/home/petya/.ssh/id_rsa_2.pub') }}"
    path: /root # но они не будут работать.
    manage_dir: False   

```
